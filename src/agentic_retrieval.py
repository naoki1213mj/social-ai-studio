"""Agentic Retrieval Tool for Azure AI Search Knowledge Base (Foundry IQ).

Provides advanced RAG capabilities with LLM-based query planning,
multi-source retrieval, and configurable reasoning effort levels.

This module integrates with Azure AI Search Knowledge Bases using the
Agentic Retrieval API (Foundry IQ), which offers:
- Query decomposition and planning (LLM-based)
- Multi-source retrieval with semantic reranking
- Configurable reasoning effort (minimal/low/medium)
- Source attribution and citations

Environment Variables:
    AI_SEARCH_ENDPOINT: Azure AI Search endpoint URL
    AI_SEARCH_KNOWLEDGE_BASE_NAME: Knowledge Base name
    AI_SEARCH_API_KEY: API key (optional if using managed identity)
    AI_SEARCH_REASONING_EFFORT: Default reasoning effort (minimal/low/medium)

Reference:
    https://learn.microsoft.com/en-us/azure/search/agentic-retrieval-how-to-set-retrieval-reasoning-effort
"""

import json
import logging
from enum import StrEnum
from typing import Annotated, Any

import httpx
from agent_framework import tool

from src.config import AI_SEARCH_API_KEY, AI_SEARCH_ENDPOINT, AI_SEARCH_KNOWLEDGE_BASE_NAME, AI_SEARCH_REASONING_EFFORT

logger = logging.getLogger(__name__)


class ReasoningEffort(StrEnum):
    """Reasoning effort levels for Agentic Retrieval."""

    MINIMAL = "minimal"  # Direct search, no LLM â€” fastest/cheapest
    LOW = "low"  # Single-pass LLM query planning â€” balanced (default)
    MEDIUM = "medium"  # Iterative search with semantic classifier â€” best quality


# API version for Agentic Retrieval
API_VERSION = "2025-11-01-preview"


def is_configured() -> bool:
    """Check if Foundry IQ is configured."""
    return bool(AI_SEARCH_ENDPOINT and AI_SEARCH_KNOWLEDGE_BASE_NAME)


async def retrieve(
    query: str,
    reasoning_effort: str | None = None,
    max_results: int = 3,
) -> dict[str, Any]:
    """Retrieve documents from Knowledge Base using Agentic Retrieval.

    Args:
        query: The search query.
        reasoning_effort: Override default effort (minimal/low/medium).
        max_results: Maximum number of results to return.

    Returns:
        Dict with sources, activity, and metadata.
    """
    if not is_configured():
        return {"error": "Foundry IQ not configured (AI_SEARCH_* env vars missing)"}

    effort = reasoning_effort or AI_SEARCH_REASONING_EFFORT
    endpoint = AI_SEARCH_ENDPOINT.rstrip("/")
    kb_name = AI_SEARCH_KNOWLEDGE_BASE_NAME

    url = f"{endpoint}/knowledgebases/{kb_name}/retrieve?api-version={API_VERSION}"

    # Build request body based on reasoning effort
    if effort == "minimal":
        # Minimal: direct intent-based search (no LLM) â€” must use intents format
        body: dict[str, Any] = {
            "intents": [{"type": "semantic", "search": query}],
            "retrievalReasoningEffort": {"kind": "minimal"},
            "includeActivity": True,
        }
    else:
        # Low/Medium: LLM-based query planning â€” must use messages format
        body = {
            "messages": [
                {
                    "role": "user",
                    "content": [{"type": "text", "text": query}],
                }
            ],
            "retrievalReasoningEffort": {"kind": effort},
            "includeActivity": True,
            "maxRuntimeInSeconds": 30,
            "maxOutputSize": 6000,
        }

    headers: dict[str, str] = {"Content-Type": "application/json"}
    # Prefer API key (local dev); fall back to DefaultAzureCredential (managed identity)
    if AI_SEARCH_API_KEY:
        headers["api-key"] = AI_SEARCH_API_KEY
    else:
        try:
            from azure.identity import DefaultAzureCredential

            credential = DefaultAzureCredential()
            token = credential.get_token("https://search.azure.com/.default")
            headers["Authorization"] = f"Bearer {token.token}"
        except Exception as e:
            logger.error("Failed to get search token: %s", e)
            return {"error": f"Authentication failed: {e}"}

    try:
        async with httpx.AsyncClient(timeout=60.0) as client:
            response = await client.post(url, json=body, headers=headers)

            if response.status_code not in (200, 206):
                error_text = response.text
                logger.error(
                    "Agentic Retrieval failed: %s - %s",
                    response.status_code,
                    error_text,
                )
                return {"error": f"Search failed: {response.status_code}"}

            result = response.json()

        # Parse response
        return _parse_response(result, effort)

    except Exception as e:
        logger.error("Agentic Retrieval error: %s", e)
        return {"error": str(e)}


def _parse_response(response: dict, effort: str) -> dict[str, Any]:
    """Parse Agentic Retrieval response into structured format."""
    response_data = response.get("response", [])
    activity = response.get("activity", [])
    references = response.get("references", [])

    sources: list[dict] = []
    for item in response_data:
        content_list = item.get("content", [])
        for content_item in content_list:
            if content_item.get("type") == "text":
                text = content_item.get("text", "")
                try:
                    parsed = json.loads(text)
                    if isinstance(parsed, list):
                        # Minimal mode returns a JSON array of {ref_id, title, content}
                        for doc in parsed:
                            sources.append(
                                {
                                    "content": doc.get("content", ""),
                                    "source": "",
                                    "title": doc.get("title", ""),
                                    "score": 0,
                                    "ref_id": doc.get("ref_id"),
                                }
                            )
                    elif isinstance(parsed, dict):
                        if "extractiveData" in parsed:
                            chunks = parsed["extractiveData"].get("chunks", [])
                            for chunk in chunks:
                                sources.append(
                                    {
                                        "content": chunk.get("content", ""),
                                        "source": chunk.get("metadata", {}).get("url", ""),
                                        "title": chunk.get("metadata", {}).get("title", ""),
                                        "score": chunk.get("rerankerScore", 0),
                                    }
                                )
                        else:
                            # Single document object
                            sources.append(
                                {
                                    "content": parsed.get("content", text),
                                    "source": parsed.get("source", ""),
                                    "title": parsed.get("title", ""),
                                    "score": parsed.get("rerankerScore", 0),
                                }
                            )
                except (json.JSONDecodeError, TypeError):
                    if text.strip():
                        sources.append({"content": text, "source": "", "title": "", "score": 0})

    # Enrich sources with reference scores
    ref_map = {str(ref.get("id", "")): ref for ref in references}
    for source in sources:
        ref_id = str(source.get("ref_id", ""))
        if ref_id in ref_map:
            ref = ref_map[ref_id]
            source["score"] = ref.get("rerankerScore", source.get("score", 0))
            if not source.get("title") and ref.get("title"):
                source["title"] = ref["title"]

    # Parse activity summary
    activity_summary = []
    for act in activity:
        act_type = act.get("type", "unknown")
        if act_type == "agenticReasoning":
            activity_summary.append(
                {
                    "type": act_type,
                    "reasoning_tokens": act.get("reasoningTokens", 0),
                }
            )
        elif act_type in ("indexedSharePoint", "searchIndex"):
            activity_summary.append(
                {
                    "type": act_type,
                    "knowledge_source": act.get("knowledgeSourceName", ""),
                    "count": act.get("count", 0),
                    "elapsed_ms": act.get("elapsedMs", 0),
                }
            )

    return {
        "sources": sources,
        "activity": activity_summary,
        "references": references,
        "reasoning_effort": effort,
    }


def _format_results(result: dict) -> str:
    """Format retrieval results for agent consumption."""
    if "error" in result:
        return f"ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {result['error']}"

    sources = result.get("sources", [])
    if not sources:
        return "é–¢é€£ã™ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"

    formatted = []
    for i, source in enumerate(sources):
        score = source.get("score", 0)
        content = source.get("content", "")
        src = source.get("source", "")
        title = source.get("title", "")

        # Truncate long content
        if len(content) > 2000:
            content = content[:2000] + "...(truncated)"

        citation = f"ã€ref_{i + 1}â€ relevance:{score:.2f}ã€‘"
        header = f"## {title}\n" if title else ""
        source_line = f"\n_Source: {src}_" if src else ""
        formatted.append(f"{header}{citation}\n{content}{source_line}")

    # Add activity summary
    activity = result.get("activity", [])
    footer_parts = [f"Reasoning Effort: {result.get('reasoning_effort', 'unknown')}"]
    for act in activity:
        if act.get("type") == "agenticReasoning":
            tokens = act.get("reasoning_tokens", 0)
            footer_parts.append(f"æŽ¨è«–ãƒˆãƒ¼ã‚¯ãƒ³: {tokens:,}")
        elif act.get("knowledge_source"):
            ks = act.get("knowledge_source", "")
            count = act.get("count", 0)
            ms = act.get("elapsed_ms", 0)
            footer_parts.append(f"{ks}: {count}ä»¶ ({ms}ms)")

    footer = f"\n\n---\nðŸ“Š {' | '.join(footer_parts)}"

    return "\n\n---\n\n".join(formatted) + footer


# ========== Agent Tool Function ========== #


@tool(approval_mode="never_require")
async def search_knowledge_base(
    query: Annotated[str, "The search query for finding relevant documents"],
    reasoning_effort: Annotated[
        str,
        "Level of LLM processing: 'minimal' (fast), 'low' (balanced), 'medium' (best quality)",
    ] = "low",
) -> str:
    """Search the knowledge base using Foundry IQ Agentic Retrieval.

    This tool provides intelligent document retrieval with:
    - Query decomposition and planning (LLM-based)
    - Multi-source retrieval with semantic reranking
    - Configurable reasoning effort for cost/quality tradeoff

    Use this tool when you need to look up brand guidelines,
    product documentation, or internal knowledge base articles.

    Args:
        query: The search query for finding relevant documents.
        reasoning_effort: Level of LLM processing.

    Returns:
        Formatted search results with citations and relevance scores.
    """
    logger.info("Foundry IQ search: query='%s', effort=%s", query, reasoning_effort)

    result = await retrieve(query, reasoning_effort)
    return _format_results(result)
